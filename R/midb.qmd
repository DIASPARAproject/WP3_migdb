---
title: "diaspara database creation script"
subtitle: "DIASPARA WP3.2 working document"
author: "Briand CÃ©dric, Oliviero Jules, Helminen Jani"
date: last-modified
date-format: "DD-MM-YYYY"
description: "Creation of the migdb Migratory fishes database, version = build"
title-block-banner: "images/diaspara_bandeau.png"
title-block-banner-color: "white"
format:
 html:
  self-contained: true
  theme: styles.scss
  smooth-scroll: true
  fontcolor: black
  toc: true
  toc-location: left
  toc-title: Summary
  toc-depth: 3
execute: 
 keep-md: true
filters:
  - include-code-files
reference-location: document
bibliography: diaspara.bib
include-after-body: "footer.html"
---


The main structure of the database has been proposed during the online diaspara meeting : [database structure](https://projets_eabx.pages.mia.inra.fr/diaspara/fr/deliverables/wp3/p2/diaspara_WP3_Tuesday_presentation.html#/section-1). 
This stucture would allow to store the data necessary to run the international stock models for the different working groups working on diadromous fishes.
The structure of the proposed database and the structure of the wgeel database are very similar. This documents creates the diaspara database, first creating referential table for the different types proposed, and then populates the database with the contents of the wgeel and wgnas database. All chunks are run sequentially to run the database, but some are later marked with eval = FALSE to speed up the process of running the quarto document.


# Hierarchical structure of the database

The database could start with the simplest structure, with a basic table
 corresponding to all data. 
Then three tables could be created, one per species. This is to allow querying 
the different tables independently. From these species tables, three different 
tables could be produced, one for data, one for parameters outputs, one for 
parameters priors. Since SQL server does not handle inheritance, once the table
 built, some of those will have to be replaced with views or partitioned views.

From these three table on could envisage the creation of specific table for 
working groups. Meaning one table for eel (wgeel), one table for salmon (wgnas),
 one table for salmon (wgbast), and one table for trutta (wgtrutta).

## Referential tables 

> [TO BE EDITED LATER WHEN WE KNOW EXACTLY WHAT WE HAVE DONE]

Similarly, referential tables could be created with a mother table 
from which specific (or wg specific) tables would inherit. 
All mother table will be held in a schema called ref.
Having working group specific tables make the setting up of consistent
foreign key more easy. For instance wgbast could reference different age class
than wgnas, and the stage would be completely different between wgeel 
and wgnas reference daughter tables. Some of these referential table
would be common between species (e.g. source from ICES vocab,
which corresponds to working group or accession events (datacalls)).

## Unicity constraints

Another important point to add (at least to the salmoglob database) 
is unicity constraint. As some values would be null, creating unicity 
constraints with indexes would be necessary. These allow to have different 
levels of constraints for instance the unicity would be defined for :
(`year, age, area, parameter`)
(`year, age, parameter`)
(`year, area, parameter`)
(`year, parameter`)

One of the table will have to contain twice the area it will have to be treated
 separately. (`year, area, area, parameter`)

# Creating the diaspara database

All along this document, the database will be named `diaspara`. 
The database is created with postgres. 

 **Some rules**

* By default values will be capitalised for the first 
 letter e.g. `Public` for the code in dataaccess. 
* Code ELE, ANG, TRT are capitalized, as are the working group names
  WGEEL, WGNAS, or country codes.
* Units are lowercase e.g. g, mm ...
* All integer used for primary keys are called `id` all text used for primary 
 keys are called `code`, the text is always called `description`.
* All tables end with a 3 letter summary which allows to identify the source of 
 one column so the table dataaccess will be called `tr_dataaccess_dta`. And the 
 column for code will be named 
* Referential tables or dictionaries are called `tr_`(sometable), tables build
 in conjuction from other tables and not in the dictionaries are called 
 `t_`(sometable).
* Foreign key are used instead of check constrainst as check constraint
 might not ensure the integrity of data after their integration (only when
 new rows are created or modified).
* Foreign key are name `fk_columnname` where the column name is the name 
in the table
* Primary keys are names `tablename_pkey` (with the constraint possibly 
referering to more than one column).
* Other constraints are check constraints `ck_columnname` and unique contraints
  `uk_columnname`
* All tables and column have a definition, we will ask the working groups
 to check those.

* Column and table name are ALWAYS LOWERCASE, the underscore is only used
 to separate type of table and table shortcode t_table_abc. In column
 is separates table code abc_def_code (table abc will reference the column
 def_code in table def).
 


```{r init}
#| echo: FALSE
#| warning: FALSE
#| message: FALSE
#| results: 'hide'

#if (!grepl("montepomi", getwd())) {
if(Sys.info()[["user"]] == 'joliviero'){
setwd("D:/workspace/DIASPARA_WP3_migdb/R")
datawd <- "D:/DIASPARA/wgbast"
} else if (Sys.info()[["user"]] == 'cedric.briand'){
setwd("C:/workspace/DIASPARA_WP3_migdb/R")
datawd <- "C:/Users/cedric.briand/OneDrive - EPTB Vilaine/Projets/DIASPARA/wgbast"
}
source("utilities/load_library.R")
load_library("tidyverse")
load_library("knitr")
load_library("kableExtra")
load_library("icesVocab")
load_library("readxl")
load_library("janitor")
load_library("skimr")
load_library("RPostgres")
load_library("yaml")
load_library("DBI")
load_library("ggplot2")
load_library("sf")
load_library("janitor") # clean_names
cred <- read_yaml("../credentials.yml")
con_diaspara <- dbConnect(Postgres(), 
                           dbname = cred$dbnamediaspara,
                           host = cred$host,
                           port = cred$port,
                           user = cred$userdiaspara,
                           password = cred$passworddiaspara)
con_diaspara_admin <- dbConnect(Postgres(), 
                           dbname = cred$dbnamediaspara,
                           host = cred$host,
                           port = cred$port,
                           user = cred$usersalmo,
                           password = cred$passwordsalmo)
con_salmoglob <- dbConnect(Postgres(), 
                           dbname = cred$dbnamesalmo,
                           host = cred$host,
                           port = cred$port,
                           user = cred$usersalmo,
                           password = cred$passwordsalmo)




```

This is run in localhost, check the wp3_habitat repository for code to set up access to the database.
In the future we will grant diaspara_admin and diaspara_read to specific users for example with a used named trout `GRANT diaspara_admin TO trout` ;

::: {.callout-note appearance="simple"}
## DIASPARA Note to self
 need to edit the pb_hba.conf on the server if not in localhost to allow access to  diaspara.
:::
 

```{r}
#| label: creatediasparadb
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to create the diaspara DB

dbExecute(con_diaspara_admin, "DROP schema if exists ref CASCADE;");
dbExecute(con_diaspara_admin, "CREATE schema ref;")
dbExecute(con_diaspara_admin, "GRANT ALL PRIVILEGES ON SCHEMA ref TO diaspara_admin ;")
dbExecute(con_diaspara_admin, "GRANT ALL PRIVILEGES ON SCHEMA public TO diaspara_read ;")
dbExecute(con_diaspara_admin, paste0("GRANT CONNECT ON DATABASE ",cred$dbnamediaspara," TO diaspara_read;"))
dbExecute(con_diaspara_admin, paste0("ALTER DATABASE ",cred$dbnamediaspara," OWNER TO diaspara_admin;"))
dbExecute(con_diaspara_admin, "DROP schema if exists refeel CASCADE;");
dbExecute(con_diaspara_admin, "CREATE SCHEMA refeel;")
dbExecute(con_diaspara_admin, "ALTER SCHEMA refeel OWNER TO diaspara_admin;")
dbExecute(con_diaspara_admin, "DROP schema if exists refnas CASCADE;");
dbExecute(con_diaspara_admin, "CREATE SCHEMA refnas;")
dbExecute(con_diaspara_admin, "ALTER SCHEMA refnas OWNER TO diaspara_admin;")
dbExecute(con_diaspara_admin, "DROP schema if exists refbast CASCADE;");
dbExecute(con_diaspara_admin, "CREATE SCHEMA refbast;")
dbExecute(con_diaspara_admin, "ALTER SCHEMA refbast OWNER TO diaspara_admin;")
dbExecute(con_diaspara_admin, "DROP schema if exists reftrutta CASCADE;");
dbExecute(con_diaspara_admin, "CREATE SCHEMA reftrutta;")
dbExecute(con_diaspara_admin, "ALTER SCHEMA reftrutta OWNER TO diaspara_admin;")

# Create foreign data wrapper to wgeel database

dbExecute(con_diaspara_admin, "CREATE EXTENSION IF NOT EXISTS postgres_fdw;")

dbExecute(con_diaspara_admin,"
CREATE SERVER wgeel_data_wrapper
  FOREIGN DATA WRAPPER postgres_fdw
  OPTIONS (host 'localhost', port '5432', dbname 'wgeel');")
dbExecute(con_diaspara_admin,"
CREATE SERVER wgnas_data_wrapper
  FOREIGN DATA WRAPPER postgres_fdw
  OPTIONS (host 'localhost', port '5432', dbname 'salmoglob');")
dbExecute(con_diaspara_admin,"
CREATE USER MAPPING FOR USER
  SERVER wgeel_data_wrapper
  OPTIONS (user 'postgres', password 'postgres');")
dbExecute(con_diaspara_admin,"  
CREATE SCHEMA refwgeel;")
dbExecute(con_diaspara_admin,"IMPORT FOREIGN SCHEMA ref    
    FROM SERVER wgeel_data_wrapper
    INTO refwgeel;")

dbExecute(con_diaspara_admin, paste0("COMMENT ON DATABASE ",cred$dbnamediaspara," IS 'This database is named Frankenstein :-)'"))    
dbExecute(con_diaspara_admin,
"GRANT ALL PRIVILEGES ON SCHEMA refwgeel TO diaspara_admin;")

```

<details> 

<summary>SQL code to additional data schema </summary>

```{#lst-schema .sql lst-cap="Building additional schema"}
--| echo: TRUE
--| eval: FALSE


-- this one is straight into sql ... 

DROP SCHEMA IF EXISTS dat CASCADE;
CREATE SCHEMA dat;
ALTER SCHEMA dat OWNER TO diaspara_admin;
COMMENT ON SCHEMA dat IS 'SCHEMA common to all migratory fish, filled by inheritance';

DROP SCHEMA IF EXISTS datang CASCADE;
CREATE SCHEMA datang;
ALTER SCHEMA datang OWNER TO diaspara_admin;
COMMENT ON SCHEMA datang IS 'SCHEMA for WGEEL';

DROP SCHEMA IF EXISTS datnas CASCADE;
CREATE SCHEMA datnas;
ALTER SCHEMA datnas OWNER TO diaspara_admin;
COMMENT ON SCHEMA datnas IS 'SCHEMA for WGNAS';

DROP SCHEMA IF EXISTS datbast CASCADE;
CREATE SCHEMA datbast;
ALTER SCHEMA datbast OWNER TO diaspara_admin;
COMMENT ON SCHEMA datbast IS 'SCHEMA for WGBAST';


DROP SCHEMA IF EXISTS dattrutta CASCADE;
CREATE SCHEMA dattrutta;
ALTER SCHEMA dattrutta OWNER TO diaspara_admin;
COMMENT ON SCHEMA dattrutta IS 'SCHEMA for WKTRUTTA';

```


</details> 

Now the database has been created with different schema (@fig-schema_diaspara). The main schema for dictionaries is ref, and a schema is created per working group for specific referential tables. The Schema refwgeel is a schema created with a foreign data wrapper to get the data from wgeel, the same schema exists for wgnas. We'll see later for wgbast and wgtrutta.



```{dot}
//| label: fig-schema_diaspara
//| fig-cap: Structure of the schema in diaspara. Dashed arrow indicate an import of data from existing 
digraph schema {
	rankdir=TB;
	size="8,5"
    node [style=filled, fillcolor=gray, shape = record];
	ref [fillcolor="gray"
       label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
       <tr> <td> <b>ref</b> </td> </tr>
       <tr> <td align="left">
        tr_species_spe <br align="left"/>
        tr_country_cou <br align="left"/>
        tr_icworkinggroup_wkg <br align="left"/>
        tr_version_ver <br align="left"/>
        tr_metric_mtr <br align="left"/>
        tr_category_cat <br align="left"/>
        tr_destination_dest <br align="left"/>
        tr_metadata_met <br align="left"/>
        tr_area_are <br align="left"/> </td> </tr> 
       </table>> 
       shape = cylinder]; 
    refeel [fillcolor="pink"
       label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
       <tr> <td> <b>refeel</b> </td> </tr>
       <tr> <td align="left">
         <br align="left"/>
         <br align="left"/>
            </td> </tr> 
       </table>> 
       shape = cylinder];
    dateel [fillcolor="pink"
       label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
       <tr> <td> <b>dateel</b> </td> </tr>
       <tr> <td align="left">
         <br align="left"/>
         <br align="left"/>
            </td> </tr> 
       </table>> 
       shape = cylinder];
    refbast [fillcolor="purple"
       label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
       <tr> <td> <b>refbast</b> </td> </tr>
       <tr> <td align="left">
         <br align="left"/>
         <br align="left"/>
            </td> </tr> 
       </table>> 
       shape = cylinder];
    datbast [fillcolor="purple"
       label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
       <tr> <td> <b>datbast</b> </td> </tr>
       <tr> <td align="left">
         <br align="left"/>
         <br align="left"/>
            </td> </tr> 
       </table>> 
       shape = cylinder];
    refnas [fillcolor="limegreen"
       label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
       <tr> <td> <b>refnas</b> </td> </tr>
       <tr> <td align="left">
         <br align="left"/>
         <br align="left"/>
            </td> </tr> 
       </table>> 
       shape = cylinder];
    datnas [fillcolor="limegreen"
       label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
       <tr> <td> <b>datnas</b> </td> </tr>
       <tr> <td align="left">
         <br align="left"/>
         <br align="left"/>
            </td> </tr> 
       </table>> 
       shape = cylinder];   
    reftrutta [fillcolor="tan1"
       label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
       <tr> <td> <b>reftrutta</b> </td> </tr>
       <tr> <td align="left">
         <br align="left"/>
         <br align="left"/>
            </td> </tr> 
       </table>> 
       shape = cylinder];
    dattrutta [fillcolor="tan1"
       label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
       <tr> <td> <b>dattrutta</b> </td> </tr>
       <tr> <td align="left">
         <br align="left"/>
         <br align="left"/>
            </td> </tr> 
       </table>> 
       shape = cylinder];   
    reftrutta;
    refwgeel;  # this in an archive
    

	refeel -> ref 
	refbast -> ref;
	refnas -> ref 
  reftrutta -> ref
  dateel -> ref
  datnas -> ref
  datbast -> ref
  dattrutta -> ref
  dateel -> refeel
  datnas -> refnas
  dattrutta -> reftrutta
  datbast  -> refbast

  refwgeel -> ref [style="dashed"]
  refwgeel -> refeel [style="dashed"]
  salmoglob -> ref [style="dashed"]
  salmoglob -> refnas [style="dashed"]

}
```

Now the database has been created with different schema (@fig-schema_diaspara). 
The main schema for dictionaries is ref, and a schema is created per working group
for specific referential tables. The Schema refwgeel has been filled in with a 
foreign data wrapper to get the data from wgeel, the same schema exists for wgnas. 
We'll see later for wgbast and wgtrutta.
The schema `dat` is the common schema for all data. 
For each working group, schema `datbast`, `dateel`, `datnas` are created.
The tables will be created in dat and later similar or a bit more complex tables
(with some more columns) will be created using the `INHERIT FROM` syntax, which
will allow to have a hierarchical structure in the db, and maintain the structure
in a table common to all fishes.
Note that`dat` should not containt any data, 
but will hold all the views and inherited tables comming from the different schema. 

# Creating referentials

## Species (tr_species_spe)

The first thing is to create a referential table for species. 
Anyways, we searched a bit for other species, even if we don't plan to start storing
data on Alosa and Lamprey it's good to prepare the database.
There are no code in ICES vocal for **Alosa alosa**, **Alosa fallax**, **Petromyzon marinus**, **Lampetra fluviatilis**.

Note CÃ©dric : Thinking later about this, I chose to get rid of `ELE` and select 
`ANG`. This column with species will be everywhere. We want to avoid generations 
of researchers to avoid what `ELE` is (apart from elephants). For the others
I've taken as close as possible to the latin name.



:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
QUESTION ICES: species code
::::
::::{.questionbox-body}
ANG,  ALA, ALF, PET, LAM are these internal code OK ?
Should we use SpecWoRMS or is Aphia OK ?

::::
:::

:::{.answerbox}
::::{.answerbox-header}
::::{.answerbox-icon}
::::
ANSWER ICES : Maria
::::
::::{.answerbox-body}
For species, we would recommend that you use AphiaIDs (a copy of which is SpecWoRMs). You can also use the FAO ASFIS list, or both, but we would recommend having the AphiaIDs for sure.
::::
:::

<details> 

<summary>Creating a referential table for species - code and queries to ICES 
</summary>

``` {r tbl-icesVocabspecies}
#| echo: TRUE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Species in ICES
#| tbl-subcap :
#|    - Code found in IC_Species
#|    - Three letter code for species. Should we use ang instead of ele ?

# No code for Lampetra, Alosa, petromyzon
sp <- getCodeList("IC_Species")
grep("Lampetra", sp$description)
grep("Petromyzon", sp$description)
grep("Alosa",  sp$description)

bind_rows(
  ele <- getCodeDetail("IC_Species","ELE")$detail,
  sal <- getCodeDetail("IC_Species","SAL")$detail,
  trs <- getCodeDetail("IC_Species","TRS")$detail) %>%
knitr::kable(caption = "Codes for migratory species in ICES, no code found for other species (Lamprey, Alosa ...)") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

if (file.exists("data/tr_species_spe_temp.Rdata")) {
  load("data/tr_species_spe_temp.Rdata") } else {
  species_list <- tibble(
    spe_code = c("SAL", "ANG", "TRT", "ALA", "ALF", "PET", "LAM"),
    spe_icspecieskey = c("SAL", "ELE", "TRT", NA,NA,NA,NA),
    spe_commonname = c("Atlantic salmon", "European eel", "Sea trout", "Twait shad", "Allis shad", "Sea lamprey", "European river lamprey"),
    spe_scientificname = c("Salmo salar", "Anguilla anguilla", "Salmo trutta", "Alosa alosa", "Alosa fallax", "Petromyzon marinus", "Lampetra fluviatilis")
  )
  tr_species_spe_temp <- species_list %>%
    rowwise() %>%
    mutate(
      spe_codeaphia = findAphia(spe_scientificname, latin = TRUE)
    ) %>%
    ungroup()
  save(tr_species_spe_temp, file = "data/tr_species_spe_temp.Rdata")
  }
  knitr::kable(tr_species_spe_temp) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
  
```

 

```{r}
#| label: species
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE

dbExecute(con_diaspara_admin, "DROP TABLE IF EXISTS ref.tr_species_spe;")
dbExecute(con_diaspara_admin,"CREATE TABLE ref.tr_species_spe (
     spe_code CHARACTER VARYING(3) PRIMARY KEY,
     spe_commonnname TEXT,
     spe_scientificname TEXT,
     spe_codeaphia numeric NOT NULL,
     spe_description TEXT)");
dbExecute(con_diaspara_admin, "GRANT ALL ON TABLE ref.tr_species_spe to diaspara_admin")
dbExecute(con_diaspara_admin, "GRANT SELECT ON TABLE ref.tr_species_spe to diaspara_read")
dbWriteTable(conn=con_diaspara, name = "tr_species_spe_temp", value = tr_species_spe_temp, overwrite = TRUE)
dbExecute(con_diaspara,"INSERT INTO ref.tr_species_spe SELECT * FROM tr_species_spe_temp")#7
dbExecute(con_diaspara,"DROP TABLE tr_species_spe_temp")
dbExecute(con_diaspara_admin, "COMMENT ON TABLE  ref.tr_species_spe IS 
'Table of fish species, spe_code SAL, ANG, TRT, ALA, ALF, PET, LAM, with 
reference to ICES vocabularies.'")
``` 

</details>

```{r tbl-species}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Working groups table in the diaspara DB
tr_icworkinggroup_wkg <- dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_species_spe")
knitr::kable(tr_icworkinggroup_wkg) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


## Working group (tr_icworkinggroup_wkg)

Species is not enough. Data will be split by working groups. Several working
groups working on the same species. There is a table for working group.
Proposed table is @tbl-icworkinggroup but need confirmation for WKTRUTTA2.

:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
QUESTION ICES/ WGTRUTTA/ DIASPARA
::::
::::{.questionbox-body}
what is the latest working group for WGTRUTTA, I found a
WKTRUTTA2 but that is quite old. Do we want to refer to other groups on diadromous
fishes there ?
The name of the WGEEL is wrong in the referential, needs to reference GFCM...
JOINT EIFAAC/ICES/GFCM WORKING GROUP ON EEL.
::::
:::

```{r}
#| label: working_group
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to create reference table for working groups 

dbExecute(con_diaspara_admin,
"DROP TABLE IF EXISTS ref.tr_icworkinggroup_wkg CASCADE;")
dbExecute(con_diaspara_admin,
"CREATE TABLE ref.tr_icworkinggroup_wkg (
wkg_code TEXT PRIMARY KEY,
wkg_description TEXT,
wkg_icesguid uuid,
wkg_stockkeylabel TEXT
);")

dbExecute(con_diaspara_admin, "COMMENT ON TABLE ref.tr_icworkinggroup_wkg 
IS 'Table corresponding to the IC_WorkingGroup referential;';")
# Using the jsonlite to download the guid also
tbl <- jsonlite::fromJSON(
  "https://vocab.ices.dk/services/api/Code/3f6fb38a-a3c5-4f5c-bf31-2045e12536ee")



temp_tr_icworkinggroup_wkg <- tbl %>%
  select(key,description,guid) %>%
  rename(wkg_code = key,
         wkg_description = description,
         wkg_icesguid = guid)%>%
  filter(wkg_code %in% c("WGEEL", "WGNAS", "WGBAST"))
temp_tr_icworkinggroup_wkg <- bind_rows(temp_tr_icworkinggroup_wkg,
                                        data.frame(wkg_code="WKTRUTTA"))
temp_tr_icworkinggroup_wkg$wkg_stockkeylabel <-
  c("sal.27.22â31","ele.2737.nea","sal.neac.all",NA)
dbWriteTable(con_diaspara_admin, 
             "temp_tr_icworkinggroup_wkg", 
             temp_tr_icworkinggroup_wkg,
             overwrite = TRUE)

dbExecute(con_diaspara_admin, "INSERT INTO ref.tr_icworkinggroup_wkg 
          SELECT 
          wkg_code,
          wkg_description,
          wkg_icesguid::uuid,
          WKG_stockkeylabel
         FROM temp_tr_icworkinggroup_wkg;") #4
dbExecute(con_diaspara_admin, "DROP TABLE temp_tr_icworkinggroup_wkg;")

dbExecute(con_diaspara_admin, "COMMENT ON COLUMN 
ref.tr_icworkinggroup_wkg.wkg_code IS 
'Working group code uppercase, WGEEL, WGNAS, WGBAST, WGTRUTTA';")


dbExecute(con_diaspara_admin, "GRANT ALL ON ref.tr_icworkinggroup_wkg 
          TO diaspara_admin;")
dbExecute(con_diaspara_admin, "GRANT SELECT ON ref.tr_icworkinggroup_wkg 
          TO diaspara_read;")
```
```{r tbl-icworkinggroup}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Working groups table in the diaspara DB
tr_icworkinggroup_wkg <- dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_icworkinggroup_wkg")
knitr::kable(tr_icworkinggroup_wkg) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

## Country (tr_country_cou)

Countries are mostly OK in the wgeel database but we need to add american countries.
The shapefiles have been downloaded from https://gisco-services.ec.europa.eu/distribution/v2/countries/download/#countries 
source EuroGeographics and UN-FAO. Countries (@tbl-country) are ordered from North to South starting from the Baltic and ending in the Mediterranean, with American number being the highest in order.

<details> 

<summary>Code to create table from wgeel and NUTS
</summary>

```{r}
#| label: country
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE

dbExecute(con_diaspara_admin, "DROP TABLE IF EXISTS ref.tr_country_cou;")
dbExecute(con_diaspara_admin, "CREATE TABLE ref.tr_country_cou (
    cou_code character varying(2) NOT NULL,
    cou_country text NOT NULL,
    cou_order integer NOT NULL,
    geom public.geometry,
    cou_iso3code character varying(3)
);")


dbExecute(con_diaspara_admin,
          "INSERT INTO ref.tr_country_cou 
          SELECT * FROM refwgeel.tr_country_cou;") #40
# Add some constraints
dbExecute(con_diaspara_admin, "ALTER TABLE ref.tr_country_cou 
          ADD CONSTRAINT t_country_cou_pkey PRIMARY KEY (cou_code);")
dbExecute(con_diaspara_admin, "ALTER TABLE ref.tr_country_cou 
          ADD CONSTRAINT uk_cou_iso3code UNIQUE (cou_iso3code);")

# missing values from America downloaded from https://gisco-services.ec.europa.eu/distribution/v2/nuts/download/ref-nuts-2024-01m.gdb.zip
# uploaded to postgres

# the tables

# ref-countries-2024-01m â CNTR_RG_01M_2024_4326
# have been copied to folder area ref-countries was renamed
# ALTER TABLE area."ref-countries-2024-01m â CNTR_RG_01M_2024_4326" 
# RENAME TO "ref-countries-2024-01m-4326";


dbExecute(con_diaspara_admin,
"INSERT INTO ref.tr_country_cou ( cou_code,
    cou_country,    
    cou_iso3code,
    geom, 
    cou_order)
SELECT \"CNTR_ID\" AS cou_code, \"NAME_ENGL\" AS cou_country,  \"ISO3_CODE\" 
AS cou_isocode, geom,
CASE WHEN \"CNTR_ID\" = 'GL' THEN 47
     WHEN \"CNTR_ID\" = 'CA' THEN 48
     ELSE 49 END AS cou_order
FROM  area.\"ref-countries-2024-01m-4326\"
WHERE \"CNTR_ID\" IN ('GL', 'CA', 'US');") #3

# Svalbard et Jan Mayen	SJM	NO Territory	
dbExecute(con_diaspara_admin,
"INSERT INTO ref.tr_country_cou ( cou_code,
    cou_country,    
    cou_iso3code,
    geom, 
    cou_order)
SELECT \"CNTR_ID\" AS cou_code, \"NAME_ENGL\" AS cou_country,  \"ISO3_CODE\" 
AS cou_isocode, geom,
CASE WHEN \"CNTR_ID\" = 'GL' THEN 47
     WHEN \"CNTR_ID\" = 'CA' THEN 48
     ELSE 49 END AS cou_order
FROM  area.\"ref-countries-2024-01m-4326\"
WHERE \"CNTR_ID\" IN ('SJ');") #3

dbExecute(con_diaspara_admin,
"UPDATE ref.tr_country_cou 
SET geom = nuts.geom  
FROM  area.\"ref-countries-2024-01m-4326\" nuts 
WHERE nuts.\"CNTR_ID\" = tr_country_cou.cou_code;") # 40

dbExecute(con_diaspara_admin,"COMMENT ON TABLE ref.tr_country_cou IS
          'Table of country codes source EuroGeographics and UN-FAO.';")
dbExecute(con_diaspara_admin,"ALTER TABLE ref.tr_country_cou 
          OWNER TO diaspara_admin;")
dbExecute(con_diaspara_admin,
          "GRANT SELECT ON TABLE ref.tr_country_cou TO diaspara_read;")
``` 


```{r tbl-country}
#| echo: TRUE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Country table in the diaspara DB
tr_country_cou <- dbGetQuery(con_diaspara, "SELECT cou_code,cou_country,cou_order, cou_iso3code FROM ref.tr_country_cou order by cou_order")
knitr::kable(tr_country_cou) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

</details> 

```{r fig-country}
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to create map from table in R
#| fig-cap: Map of countries in the diaspara DB &copy; [EuroGeographics](https://gisco-services.ec.europa.eu/distribution/v2/nuts/download/)

if (file.exists("data/country_sf.Rdata")) load("data/country_sf.Rdata") else {
country_sf <- sf::st_read(con_diaspara,
                          query = "SELECT cou_code, ST_MakeValid(geom) 
                          from ref.tr_country_cou") %>%
  sf::st_transform(4326) 
save(country_sf, file="data/country_sf.Rdata")
}
#see here : https://stackoverflow.com/questions/70756215/
#plot-geodata-on-the-globe-perspective-in-r
# Note there is a problem of geometry for some of the polygons, and this require 
# ST_Makevalid before intersection

# projection string used for the polygons & ocean background
crs_string <- "+proj=ortho +lon_0=-30 +lat_0=30"

# background for the globe - center buffered by earth radius
ocean <- sf::st_point(x = c(0,0)) %>%
  sf::st_buffer(dist = 6371000) %>%
  sf::st_sfc(crs = crs_string)
country_sf2 <-  country_sf %>% 
  sf::st_intersection(ocean %>% sf::st_transform(4326)) %>% 
  # select visible area only
  sf::st_transform(crs = crs_string) # reproject to ortho
# now the action!
g <- ggplot(data = country_sf2) +
  geom_sf(data = ocean, fill = "aliceblue", color = NA) + # background first
  geom_sf(aes(fill = cou_code), lwd = .1) + # now land over the oceans
  scale_fill_discrete(guide = "none") +
  theme_void()

# this part is used to avoid long computations
png(filename="images/fig-country.png", bg="transparent")
print(g)
dev.off()

```
![Map of countries in the diaspara DB &copy; [EuroGeographics](https://gisco-services.ec.europa.eu/distribution/v2/nuts/download/)](images/fig-country.png "A planisphere with countries in migdb"){#fig-country}

## Unit (tr_units_uni)


<details> 

<summary>Creating the unit from wgeel and checking ICES code </summary>
First we import from wgeel

Then we standarize using ICES codes, it takes a while to scroll through the vocab.
Sometimes several vocab are available for the same thing. We used the p06 as the
most common source. Hopefully that was the right choices ?

```{r}
#| label: unit
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE


dbExecute(con_diaspara_admin, "DROP TABLE IF EXISTS ref.tr_units_uni CASCADE;")

dbExecute(con_diaspara_admin,
"CREATE TABLE ref.tr_units_uni (
	uni_code varchar(20) NOT NULL,
	uni_description text NOT NULL,
  uni_icesvalue character varying(4),  uni_icesguid uuid,
  uni_icestablesource text,
	CONSTRAINT t_units_uni_pkey PRIMARY KEY (uni_code),
	CONSTRAINT uk_uni_description UNIQUE (uni_description),
  CONSTRAINT uk_uni_icesguid UNIQUE (uni_icesguid),
  CONSTRAINT uk_uni_icesvalue UNIQUE (uni_icesvalue)
);")

dbExecute(con_diaspara_admin,"INSERT INTO ref.tr_units_uni (
uni_code, uni_description)
SELECT * FROM refwgeel.tr_units_uni;")#25

dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='KGXX' 
          where uni_code = 'kg';") 
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='MTON'
          where uni_code = 't';") 
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='UCNT' 
          where uni_code = 'nr';") 
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='UGRM' 
          where uni_code = 'g';")
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='UPMS'
          where uni_code = 'nr/m2';")
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='UPMM' 
          where uni_code = 'nr/m3';")
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='UYRS' 
          where uni_code = 'nr year';")
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='UXMM' 
          where uni_code = 'mm';")
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='NGPG' 
          where uni_code = 'ng/g';")
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='HCTR' 
          where uni_code = 'ha';")
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='UTAA' 
          where uni_code = 'nr day';")
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='NOPH'
          where uni_code = 'nr/h';")
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='NGPG'
          where uni_code = 'ng/g';")
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='UPCT'
          where uni_code = 'percent';")
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set 
          (uni_icesvalue, uni_description)=
          ('XXXX', 'Not applicable (without unit)')
          where uni_code = 'wo';")          

dbExecute(con_diaspara_admin, "INSERT INTO ref.tr_units_uni 
          VALUES ('year-1', 'Per year', 'XXPY');")          
dbExecute(con_diaspara_admin, "INSERT INTO ref.tr_units_uni 
          VALUES ('s', 'Seconds', 'UTBB');")



p06 <- icesVocab::getCodeList('p06')
SamplingUnit <- icesVocab::getCodeList('SamplingUnit')
uni <- dbGetQuery(con_diaspara_admin, "SELECT * FROM ref.tr_units_uni;")
tempuni <- inner_join(uni, p06, by=join_by(uni_icesvalue==Key))
dbWriteTable(con_diaspara_admin, "tempuni", tempuni, overwrite=TRUE)
dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni 
set uni_icesguid = \"GUID\"::uuid
          FROM tempuni 
          where tempuni.uni_icesvalue=tr_units_uni.uni_icesvalue;") #16
dbExecute(con_diaspara_admin, "DROP TABLE tempuni;")

dbExecute(con_diaspara_admin,
"UPDATE ref.tr_units_uni set uni_icestablesource = 'p06' where uni_icesvalue 
IS NOT NULL AND
uni_icestablesource IS NULL;") # 16

query <- sprintf("INSERT INTO ref.tr_units_uni (uni_code,uni_description, uni_icesvalue, uni_icestablesource,uni_icesguid) VALUES ('%s','%s','%s','%s','%s'::uuid);", 
                 "gd", 
                 "Gear days for fyke/trap nets",
                 "gd", 
                 "MUNIT",
                 "bf0570b7-45f2-41c7-9a46-de912a2b9ad4")              
dbExecute(con_diaspara_admin,  query)


dbExecute(con_diaspara_admin, "UPDATE ref.tr_units_uni set uni_icesvalue='idx', 
          uni_icestablesource = 'MUNIT',
          uni_icesguid ='87a9cf7f-fff4-4712-b693-76eec1403254'::uuid
          where uni_code = 'index';")

# p06[grep('Ton',p06$Description),c("Description","Key")] 
# p06[grep('Without',tolower(p06$Description)),c("Description","Key")] 
# p06[grep('nanogram',tolower(p06$Description)),c("Description","Key")]
# p06[grep('index',tolower(p06$Description)),c("Description","Key")]
# p06[grep('hour',tolower(p06$Description)),c("Description","Key")]
# p06[grep('kilogram',tolower(p06$Description)),c("Description","Key")]
# p06[grep('nanogram',tolower(p06$Description)),c("Description","Key")]
# p06[grep('haul',tolower(p06$Description)),c("Description","Key")]

dbExecute(con_diaspara_admin, "COMMENT ON TABLE ref.tr_units_uni IS 
'Table of units, values from tables MUNIT and p06 have corresponding ICES code.'")
dbExecute(con_diaspara_admin, "COMMENT ON COLUMN ref.tr_units_uni.uni_code IS 
'Unit code, lowercase, nr number, otherwise standard units.'")
dbExecute(con_diaspara_admin, "COMMENT ON COLUMN ref.tr_units_uni.uni_description
 IS 'Unit code, lowercase, nr number, otherwise standard units.'")
dbExecute(con_diaspara_admin, "COMMENT ON COLUMN ref.tr_units_uni.uni_icesvalue IS 
'ICES code standard from the British Oceanographic Data Centre (p06) or MUNIT 
table.';") 
dbExecute(con_diaspara_admin, 
"COMMENT ON COLUMN ref.tr_units_uni.uni_icestablesource IS 
'Table source in ICES.';") 
dbExecute(con_diaspara_admin, 
"COMMENT ON COLUMN ref.tr_units_uni.uni_icesguid IS 
'GUID, type https://vocab.ices.dk/?codetypeguid=<guidcode> to get access to the 
vocab in ICES.';") 
dbExecute(con_diaspara_admin, "GRANT ALL ON TABLE ref.tr_units_uni 
          to diaspara_admin;")
dbExecute(con_diaspara_admin, "GRANT SELECT ON TABLE ref.tr_units_uni 
          to diaspara_read;")
``` 

</details> 



```{r}
#| label: tbl-unit
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: tr_units_uni table, check missing values currently not found in ICES Vocab
dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_units_uni;")%>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
``` 

Some of the values are missing from ICES vocab (Table @tbl-unit).

:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
QUESTION ICES: missing values for units, what do we do ?
::::
::::{.questionbox-body}
What do we do with units without correspondance? These come from FAO
(if I remember well). Do we try to search for those in the wgeel database, and 
then remove if not existing or try to change existing values ?

* Kg/day there is a kg/hour do we need to change to that type and convert existing 
series ?

* Nr haul There is a definition of haul in the ICES vocab but it seems very related
to sampling box, basket. And it's not the number of haul.

* Before working any further I would like your opinion there.
::::
:::



## Parameters

Parameters are a simple way to reduce the complexity of data. It will correspond to all nimble variables, reduced to their lower level (e.g. 3 dimensional arrays with dimensions [area, year, stage] will be translated as many lines with the corresponding values in columns area, year, and stage), and the identifyer of the variable will be used for all the lines necessary to store this dataset. In practise, parameters also correspond to input data, and output data in the model.
The parameters will be described by their metadata as illustrated in @fig-metadata

![Mind map of the metadata structure](images\SAM_parm_metadata.png){#fig-metadata}

We can have a look at the metadata in the analysis done on the WGNAS database [WGNAS description](https://projets_eabx.pages.mia.inra.fr/diaspara/fr/deliverables/wp3/p4/wgnas_salmoglob_description.html#metadata).

There is a problem in the "order or the dimensions which need to be aligned. For instance a column can hold year, or age. This is not good. The description could be used within a type [array](https://www.postgresql.org/docs/current/arrays.html).
SQL server does not work with array so it's not a good idea to use those. 


<details> 

<summary>Checking stock codes using icesASD and icesSD packages</summary>

```{r tbl-advice}
#| echo: TRUE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Access to the advice using icesASD

# install.packages('icesASD', repos = c('https://ices-tools-prod.r-universe.dev', 'https://cloud.r-project.org'))
#install.packages("icesSD", repos = c("https://ices-tools-prod.r-universe.dev", "https://cloud.r-project.org"))

library('icesASD')
library('icesSD')
# this does not give the 
advice <- getAdviceViewRecord()
advice[grepl('ele',advice$stockCode),
       c('adviceDOI', 'stockCode','assessmentYear')] %>% kable
sd <- mapply(getSD, year= 2020:2024, SIMPLIFY=FALSE)
sd <- do.call(rbind,sd)
ww <- grepl('ele',sd$StockKeyLabel) | grepl('Salmo',sd$SpeciesScientificName)
sd[ww,] %>% kable()

```

</details> 


The code for creating metadata is listed below

<details> 

<summary>SQL code to create tables</summary>

```{.sql include="../SQL/2_tr_metadata_met.sql"}
```
</details> 



::: {.callout-note appearance="simple"}
## DIASPARA
 Not yet completely sure about this ....
 Environment (sea, transition ...), age, life stage and complex are in the metadata.
 But they are also in the main table.
To start with, we remove them to reduce complexity and avoid errors.
 The `complex` will be derived from the spatial structure still in construction
:::

::: {.callout-note appearance="simple"}
## DIASPARA
 As in the diagram, added a category (data type in figure @fig-metadata).
 The idea is to be able to get quickly all parameters related to a type, 
 e.g. catch, mortality, biomass. Please check and also check definitions.
:::

::: {.callout-note appearance="simple"}
## DIASPARA
 WGBAST, WGNAS, WGEEL, WGTRUTTA will have to check definitions in tr_destination_dest.
 Note this is just a column in tr_metadata_met not in the main table. Check if it could not simply be removed if the definition of the parameter is clear ?
:::


## Object type (tr_objectype_oty)

This table (@tbl-objectype) is used in metadata 

```{r}
#| label: tbl-objectype
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Object type

dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_objecttype_oty;")%>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))


``` 

## Type of parm / data (tr_nimble_nim)

In the salmoglob db, this table (@tbl-nimble) corresponded to both tables status and nimble 
which most often contained the same information.

```{r}
#| label: tbl-nimble
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Nimble

dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_nimble_nim;")%>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

``` 

## Version (tr_version_ver)

Currently in the salmoglob metadata there is no information about version.
The version number is in the table itself. It seems to correspond to different 
versions of the same parameter.
While currently this information is stored in the `database` and `database_archive` it seems to that metadata should also contain 
information about historical variables.
For instance we create a new variable, so we know when it was introduced.
So in addition with the data in the main table I'm adding a version number to metadata, 
Some variables might get deprecated over time. The year will be the year
when the variable was introduced. All variables in this version of the DB in metadata
will start with SAL-2024-1, the tr_version_ver should be able to store a version number
but currently I need to understand to what it corresponds.

Note that the version (@tbl-version) contains both reference to the datacall (when data are loaded)
and to the advice. The advice might still be null at the time the values
will be entered into the database.
The version will be handled in inherited tables for WGNAS, WGEEL and WGBAST.
Here I'm currently entering the WGNAS data.

:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
Question to WNGAS / Etienne
::::
::::{.questionbox-body}
Check that this is correct, original values in the table metadata were 
"Const_nimble" "Data_nimble"  "Output"       "other"  
::::
:::




```{r }
#| label: tr_version_ver_insert
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to insert values into the tr_version_ver table

#sd <-do.call(rbind,mapply(icesSD::getSD, year= 2020:2024, SIMPLIFY=FALSE))
#sd[grepl('Working Group on North Atlantic Salmon',sd$ExpertGroupDescription),]
 


tr_version_ver <- data.frame(
ver_code = paste0("SAL-",2020:2024,"-1"),
ver_year = 2020:2024,
ver_spe_code = "SAL",
ver_datacalldoi=c(NA,NA,NA,NA,"https://doi.org/10.17895/ices.pub.25071005.v3"), 
ver_stockkeylabel =c("sal.neac.all"), # sugested by Hilaire. 
# TODO FIND other DOI (mail sent to ICES)
ver_version=c(1,1,1,1,1), # TODO WGNAS check that there is just one version per year
ver_description=c(NA,NA,NA,NA,NA)) # TODO WGNAS provide model description

DBI::dbWriteTable(con_diaspara_admin, "temp_tr_version_ver", tr_version_ver, 
overwrite = TRUE)
dbExecute(con_diaspara_admin, "INSERT INTO refnas.tr_version_ver SELECT * FROM temp_tr_version_ver;") # 5
 DBI::dbExecute(con_diaspara_admin, "DROP TABLE temp_tr_version_ver;")


# TODO eel and wgbast
#"ele.2737.nea","sal.27.22â31",

```

:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
Question to WNGAS / ICES
::::
::::{.questionbox-body}
* Check there is just one version per year
* Provide descriptions of the version of the model
* Questions sent to ICES to provide access to historical DOI
* Exchanges currently on this (17/03/2025) with Etienne / Pierre Yves Hernvann
::::
:::

```{r}
#| label: tbl-version
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Version

dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_version_ver;")%>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

``` 

:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
QUESTION ICES: What is the vocabulary for datacalls
::::
::::{.questionbox-body}
I would like to access to this table : [datacall (see link in ICES webpage)](https://data.ices.dk/DataCalls/listDataCalls).
Currently we see the current year, this is nice, how do we access to historical data, is there a way to get it using a query ?
We've found a link for advice or stocks but not data calls.

::::
:::

## Metric (tr_metric_mtr)

```{r tbl-metric}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap : Metric, type of parm used in the model

dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_metric_mtr;")%>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

``` 

::: {.callout-note appearance="simple"}
## NOTE
This list is probably incomplete. But the metric can be NULL in case of a number
of fish released, not of the above (@tbl-metric) will apply.
:::



## Category (tr_category_cat)

categories @Tbl-category were in the salmoglob metadata, we have simplified to reduce the number of categories
and be able to get for instance all parameters dealing with catch.

```{r}
#| label: tbl-category
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: category of parameters
dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_category_cat;")%>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```

## Destination (tr_destination_dest)


A bit cumbersome this table, the idea is "what becomes of this fish". 
Different types of landings.
But it's just in metatdata and we need need in WGBAST

```{r}
#| label: tbl-destination
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: category of parameters
dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_destination_des;") %>% 
knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

``` 

:::{.callout-note appearance="simple"}
## NOTE DIASPARA
Here Hilaire say that naming the table "outcome" wasn't ideal so I've followed his suggestion
:::


## Metadata (tr_metadata_met)




```{r}
#| label: tbl-metadata
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: metadata
dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_metadata_met;")%>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

``` 



## Area (tr_area_are)


Here I'm trying to build something consistent. I guess only the final result 
will tell but I have to start somewhere ...
A good idea to simploify the structure of the db is to get together marine
and continental areas. 

### Continental areas

```{r}
#| label: area
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to create area


dbExecute(con_diaspara_admin,
"DROP TABLE IF EXISTS ref.tr_level_lev CASCADE;")

dbExecute(con_diaspara_admin,
"CREATE TABLE ref.tr_level_lev(
   lev_code TEXT PRIMARY KEY,
   lev_description TEXT  
);")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'Panpopulation',
  'This is the highest geographic level for assessement.'  
  );")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'Complex',
  'Corresponds to large sublevels at which the Panpopulation is assessed, e.g.
  NAC NEC for WGNAST, Gulf of Bothnia for WGBAST, Mediterranean for WGEEL.'  
  );")

  dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'Stock',
  'Correspond to stock units for which advices are provided in ICES, this can be the level of the panpopulation,
  or another level e.g. .'  
  );")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'Country',
  'Corresponds to one or more units, but in almost all stocks
  this level is relevant to split data.'
  );")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'Assessment_unit',
  'Corresponds to an assessment unit in the Baltic sea, and area for  
  WGNAS, and EMU for WGEEL.'
  );")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'Regional',
  'Corresponds to subunits of stock assessment units or 
  basins grouping several river. Although it is not used yet for
  some models, regional genetic difference or difference in stock
  dynamic support collecting a regional level.'
  );")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'River',
  'One river is a unit corresponding practically almost always to a watershed.'
  );")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'river_section',
  'Section of river, only a part of a basin, for instance to separate between
  wild and mixed river category in the Baltic.'
  );")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'Major',
  'Major fishing areas from ICES.'
  );")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'Subarea',
  'Subarea from ICES, FAO and NAFO'
  );")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'Division',
  'Division from ICES, GFCM and NAFO'
  );")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_level_lev VALUES( 
  'Subdivision',
  'Subdivision level from ICES, GFCM and NAFO'
  );")

dbExecute(con_diaspara_admin, "COMMENT ON TABLE ref.tr_level_lev 
IS 'Table of geographic levels stock, complex, country, region, basin, river,
the specific order depend according to working groups.';")

dbExecute(con_diaspara_admin, "GRANT ALL ON ref.tr_level_lev 
          TO diaspara_admin;")
dbExecute(con_diaspara_admin, "GRANT SELECT ON ref.tr_level_lev 
          TO diaspara_read;")


dbExecute(con_diaspara_admin,
"DROP TABLE IF EXISTS ref.tr_area_are CASCADE;")
dbExecute(con_diaspara_admin,
"CREATE TABLE ref.tr_area_are (
   are_id INTEGER PRIMARY KEY,
   are_are_id INTEGER,
   are_code  TEXT,
   are_lev_code TEXT,
   are_wkg_code TEXT,
   are_ismarine BOOLEAN,
   geom geometry(MULTIPOLYGON, 4326),
  CONSTRAINT fk_are_are_id FOREIGN KEY (are_are_id) 
  REFERENCES ref.tr_area_are (are_id) ON DELETE CASCADE
  ON UPDATE CASCADE,
  CONSTRAINT uk_are_code UNIQUE (are_code),
  CONSTRAINT fk_area_lev_code FOREIGN KEY (are_lev_code) REFERENCES
  ref.tr_level_lev(lev_code) ON UPDATE CASCADE ON DELETE CASCADE,
  CONSTRAINT fk_area_wkg_code FOREIGN KEY (are_wkg_code) REFERENCES
  ref.tr_icworkinggroup_wkg(wkg_code) ON UPDATE CASCADE ON DELETE CASCADE
);")

dbExecute(con_diaspara_admin, "GRANT ALL ON ref.tr_area_are 
          TO diaspara_admin;")
dbExecute(con_diaspara_admin, "GRANT SELECT ON ref.tr_area_are 
          TO diaspara_read;")

dbExecute(con_diaspara_admin, "COMMENT ON TABLE ref.tr_area_are 
IS 'Table corresponding to different geographic levels, from stock 
to river section.';")

```

```{r}
#| label: tbl-level
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Geographical level tr_level_lev
dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_level_lev;")%>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

``` 

:::{.callout-note appearance="simple"}
## Note from Hilaire
The working groups might change over time, referencing a working group there is probably not the best.
CÃ©dric : Added stockkeylabel, this table is necessary to aggregate data (species is not enough).
:::



```{r}
#| label: tbl-area
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Geographic areas
dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_area_are;")%>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

``` 

```{dot}
//| label: fig-area_hierarchy
//| fig-cap: The nested structure layed out in table tr_area_area, dotted box indicate that the level is optional. This table will be created specifically for each group.


digraph {
    compound=true;
    newrank=true;

    subgraph clusterA {
      label = Panpopulation
      style=full
      color=black
      center=true

      subgraph clusterB {
        label = Complex
        style=dashed
        color=black
        center=true

              subgraph clusterC {
              label = Stock
              style=dashed
              color=black
              center=true
    
                subgraph clusterD {
                  label = Country
                  style=dashed
                  color=firebrick
                  fontcolor=firebrick
                  center=true

                  subgraph clusterE {
                    label = Assessment_unit
                    style=full
                    color=green 
                    fontcolor=green
                    
                      subgraph clusterF {
                        label = Regional;
                        style=dashed
                        color=green4
                        fontcolor=green4
                        
                          subgraph clusterG {
                            label = River
                            style=dashed
                            color=green3
                            fontcolor=green3
                            
                                subgraph clusterH {
                                        label = River_section
                                        style=dashed
                                        color=green2
                                        fontcolor=green2
                                            section [
                                                label=data,
                                                shape=box, 
                                                style =invis
                                                ]
                                }
                          }
                      }
                  }
                }
              }
        subgraph clusterZ{
          label=Major
          style=dashed
          color=royalblue4
          fontcolor=royalblue4
          
                subgraph clusterY{
                    label=Subareas
                    style=dashed
                    color=royalblue3
                    fontcolor=royalblue3
                    
                        subgraph clusterX{
                            label=Division
                            style=dashed
                            color=royalblue2
                            fontcolor=royalblue2
                            
                                subgraph clusterW{
                                    label=Sudivision
                                    style=full
                                    color=royalblue1
                                    fontcolor=royalblue1
                                    
                                       subgraph clusterV{
                                           label=Unit
                                            style=dashed
                                            color=deepskyblue
                                            fontcolor=deepskyblue
                                            
                                                Fishing [
                                                    style=invis]
                                       }
                                }
                        }
                }            
        }          
      }}}
```

## Data access (tr_dataaccess_dta)

Type of data Public, or Restricted
```{r}
#| label: access
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to create dataaccess tr_dataaccess_dta


dbExecute(con_diaspara_admin,
"DROP TABLE IF EXISTS ref.tr_dataaccess_dta CASCADE;")

dbExecute(con_diaspara_admin,
"CREATE TABLE ref.tr_dataaccess_dta(
   dta_code TEXT PRIMARY KEY,
   dta_description TEXT  
);")


tr_dataaccess_dta <- dbGetQuery(con_diaspara_admin, 
"SELECT * FROM refwgeel.tr_dataaccess_dta")

dbExecute(con_diaspara_admin,
  "INSERT INTO ref.tr_dataaccess_dta 
  SELECT * FROM refwgeel.tr_dataaccess_dta
  ;")#2

dbExecute(con_diaspara_admin, "GRANT ALL ON ref.tr_dataaccess_dta 
          TO diaspara_admin;")
dbExecute(con_diaspara_admin, "GRANT SELECT ON ref.tr_dataaccess_dta 
          TO diaspara_read;")

dbExecute(con_diaspara_admin, "COMMENT ON TABLE ref.tr_dataaccess_dta 
IS 'Table with two values, Public or Restricted access.';")

```

## Missing data (tr_missvalueqal_mis)

This comes from wgeel.

```{r}
#| label: missvaluequal
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to create tr_missvalueqal_mis


dbExecute(con_diaspara_admin,
"DROP TABLE IF EXISTS ref.tr_missvalueqal_mis CASCADE;")

dbExecute(con_diaspara_admin,
"CREATE TABLE ref.tr_missvalueqal_mis(
   mis_code TEXT PRIMARY KEY,
   mis_description TEXT NOT NULL,  
   mis_definition TEXT);")

dbExecute(con_diaspara_admin,
"INSERT INTO ref.tr_missvalueqal_mis 
SELECT
'NR',
'Not reported',	
'Data or activity exist but numbers are not reported to authorities (for example for commercial confidentiality reasons).';")
dbExecute(con_diaspara_admin,
"INSERT INTO ref.tr_missvalueqal_mis 
SELECT
'NC',	
'Not collected',	
'Activity / habitat exists but data are not collected by authorities (for example where a fishery exists but the catch data are not collected at the relevant level or at all).';")
dbExecute(con_diaspara_admin,
"INSERT INTO ref.tr_missvalueqal_mis 
SELECT
'NP',	
'Not pertinent',
'Where the question asked does not apply to the individual case (for example where catch data are absent as there is no fishery or where a habitat type does not exist in a stock unit).';")

dbExecute(con_diaspara_admin, "GRANT ALL ON ref.tr_missvalueqal_mis 
          TO diaspara_admin;")
dbExecute(con_diaspara_admin, "GRANT SELECT ON ref.tr_missvalueqal_mis 
          TO diaspara_read;")

dbExecute(con_diaspara_admin, "COMMENT ON TABLE ref.tr_missvalueqal_mis 
IS 'Table showing the qualification when value is missing, NC, NP, NR.';")
```

```{r}
#| label: tbl-missvaluequal
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Code for missing values
dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_missvalueqal_mis;")%>% 
knitr::kable() %>% 
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

``` 

# ICES areas

Download shapefiles from NAFO => 
create table following ICES_Areas for GUID
FAO major fishing area (27, 21, 37, 34, 31)
27 Atlantic, Northeast
21 Atlantic, Northwest
37 Mediterranean and Black Sea
34 Atlantic, Eastern Central
31 Atlantic, Western Central
subarea
division
subdivision

code 27.9.b.2 area_full
area_27 9.b.2

source : GFCM geographical subareas
https://www.fao.org/gfcm/data/maps/gsas/fr/
https://gfcmsitestorage.blob.core.windows.net/website/5.Data/ArcGIS/GSAs_simplified_updated_division%20(2).zip

source : NAFO divisions
https://www.nafo.int/Data/GIS
https://www.nafo.int/Portals/0/GIS/Divisions.zip

source : ICES statistical areas
https://gis.ices.dk/shapefiles/ICES_areas.zip
https://gis.ices.dk/geonetwork/srv/eng/catalog.search#/metadata/c784a0a3-752f-4b50-b02f-f225f6c815eb

The rest of the word was somewhere on my computer. Cannot trace the source,
it's exaclty the same for NAFO but changed in the med and ICES. For some reasons
was not complete in table from wgeel so have to download it again to postgres.

Values for geom have been updated from ICES areas, the new boundaries are 
different, however, more than the previous ones. The values for Areas and Subareas
have not been updated but these are for wide maps so we'll leave it as it is.


```{r}
#| label: fishingareas
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to create reference fishing area maps 

dbExecute(con_diaspara_admin, "DROP TABLE IF EXISTS ref.tr_fishingarea_fia 
CASCADE;")
dbExecute(con_diaspara_admin,
"
  CREATE TABLE ref.tr_fishingarea_fia
  (  
    fia_level TEXT,
    fia_code TEXT,
    fia_status numeric,
    fia_ocean TEXT,
    fia_subocean TEXT,
    fia_area TEXT,
    fia_subarea TEXT,
    fia_division TEXT,
    fia_subdivision TEXT,
    fia_unit TEXT,
    fia_name TEXT NULL,
    geom geometry(MultiPolygon,4326),
    CONSTRAINT tr_fishingarea_fia_pkey PRIMARY KEY (fia_code),
    CONSTRAINT uk_fia_subdivision UNIQUE (fia_unit)
  )
  ;
")


# start with initial FAO dataset

#area_all <- dbGetQuery(con_diaspara_admin, "SELECT * FROM area.\"FAO_AREAS\"
# WHERE f_area IN ('21','27','31','34','37') ;")

# In this table all geom are mixed from unit to division.
# It only make sense to extract for a unique f_level


# TODO add species, wk
dbExecute(con_diaspara_admin, "INSERT INTO ref.tr_fishingarea_fia
SELECT
   initcap(f_level) AS fia_level, 
   f_code AS  fia_code,
   f_status AS  fia_status,
   ocean AS  fia_ocean,
   subocean AS  fia_subocean,
   f_area AS  fia_area,
   f_subarea AS  fia_subarea,
   f_division AS  fia_division,
   f_subdivis AS  fia_subdivision,
   f_subunit AS  fia_unit,
   NULL as fia_name,
   geom 
  FROM area.\"FAO_AREAS\"
  WHERE f_area IN ('21','27','31','34','37') 
") # 187

# Replace values ices
dbExecute(con_diaspara_admin, "UPDATE ref.tr_fishingarea_fia
    set geom = st_transform(are.geom, 4326)
    FROM
    area.\"ICES_Areas_20160601_cut_dense_3857\" are
    WHERE area_full = fia_code;") # 66
# Replace values NAFO (nothing to do ...)



# Replace values GFCM
dbExecute(con_diaspara_admin, "INSERT INTO ref.tr_fishingarea_fia
SELECT 
'Subdivision' AS fia_level, 
f_gsa AS fia_code,
1 AS fia_status,
'Atlantic' AS fia_ocean, 
3 AS fia_subocean, 
f_area, 
f_subarea, 
f_division, 
f_gsa AS fia_subdivision,
NULL AS fia_unit,
smu_name AS fia_name,
geom
FROM area.\"GSAs_simplified_division\";") # 32

dbExecute(con_diaspara_admin, "GRANT ALL ON ref.tr_fishingarea_fia 
          TO diaspara_admin;")
dbExecute(con_diaspara_admin, "GRANT SELECT ON ref.tr_fishingarea_fia 
          TO diaspara_read;")

dbExecute(con_diaspara_admin, "COMMENT ON TABLE ref.tr_fishingarea_fia 
IS 'Table of fishing areas, attention, different levels of geometry
details are present in the table, area, subarea, division, subdivision, unit,
most query will use WHERE 
 fia_level = ''Subdivision''';")
``` 

```{r fig-fishingareas_major}
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Coderedce  to create a map of fishing areas at Major level
#| fig-cap: Map of ICES fishing areas at Major level, source NAFO, FAO, ICES, GFCM.

library(rnaturalearth)
world <- ne_countries(scale = "small", returnclass = "sf")


if (file.exists("data/fishingareas_major.Rdata")) 
load("data/fishingareas_major.Rdata") else {
fishing_areas_major <- sf::st_read(con_diaspara,
                          query = "SELECT fia_code, ST_MakeValid(geom) 
                          from ref.tr_fishingarea_fia
                          WHERE fia_level = 'Major'") %>%
  sf::st_transform(4326) 
save(fishing_areas_major, file="data/fishing_areas_major.Rdata")
}
load("data/country_sf.Rdata")
crs_string <- "+proj=ortho +lon_0=-30 +lat_0=30"

ocean <- sf::st_point(x = c(0,0)) %>%
  sf::st_buffer(dist = 6371000) %>%
  sf::st_sfc(crs = crs_string)
area_sf2 <-  fishing_areas_major %>% 
  sf::st_intersection(ocean %>% sf::st_transform(4326)) %>% 
  sf::st_transform(crs = crs_string) 

country_sf2 <-  country_sf %>% 
  sf::st_intersection(ocean %>% sf::st_transform(4326)) %>% 
  sf::st_transform(crs = crs_string) 



g <- ggplot() + 
  geom_sf(data = ocean, fill = "deepskyblue4", color = NA) + 
  geom_sf(data = area_sf2, aes(fill = fia_code), color="white", lwd = .1) + 
  geom_sf(data = world, fill="black", color="grey20") + 
  geom_sf(data= country_sf2 , fill= "grey10",color="grey30")  +
  theme_void()
  #scale_fill_discrete(guide = "none") +

  
# this part is used to avoid long computations
png(filename="images/fig-fishingareas_major.png",width=600, height=600, res=300, bg="transparent")
print(g)
dev.off()


```

![ Map of ICES fishing areas at Major level, source NAFO, FAO, ICES, GFCM.](images/fig-fishingareas_major.png "A planisphere with ocean major fishing areas"){#fig-fishingareas_major}

```{r fig-fishingareas_subarea}
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to create a map of fishing areas at Subarea level
#| fig-cap: Map of ICES fishing areas at Subarea level, source NAFO, FAO, ICES, GFCM.

if (file.exists("data/fishingareas_subarea.Rdata")) load("data/fishingareas_subarea.Rdata") else {
fishing_areas_subarea <- sf::st_read(con_diaspara,
                          query = "SELECT fia_code, ST_MakeValid(geom) 
                          from ref.tr_fishingarea_fia
                          WHERE fia_level = 'Subarea'") %>%
  sf::st_transform(4326) 
save(fishing_areas_subarea, file="data/fishing_areas_subarea.Rdata")
}
crs_string <- "+proj=ortho +lon_0=-30 +lat_0=30"

area_sf2 <-  fishing_areas_subarea %>% 
  sf::st_intersection(ocean %>% sf::st_transform(4326)) %>% 
  sf::st_transform(crs = crs_string) # reproject to ortho

g <- ggplot() + 
  geom_sf(data = ocean, fill = "deepskyblue4", color = NA) + 
  geom_sf(data = area_sf2, aes(fill = fia_code), color="white", lwd = .1) + 
  geom_sf(data = world, fill="black", color="grey20") + 
  geom_sf(data= country_sf2 , fill= "grey10",color="grey30")  +
  scale_fill_discrete(guide = "none")  +
  theme_void()

# this part is used to avoid long computations
png(filename="images/fig-fishingareas_subarea.png", bg="transparent")
print(g)
dev.off()

```


![ Map of ICES fishing areas at Subarea level, source NAFO, FAO, ICES, GFCM.](images/fig-fishingareas_subarea.png "A planisphere with ocean fishing subareas"){#fig-fishingareas_subarea}

```{r fig-fishingareas_division}
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to create a map of fishing areas at Division level
#| fig-cap: Map of ICES fishing areas at Division level, source NAFO, FAO, ICES, GFCM.

if (file.exists("data/fishingareas_division.Rdata")) load("data/fishingareas_division.Rdata") else {
fishing_areas_division <- sf::st_read(con_diaspara,
                          query = "SELECT fia_code, ST_MakeValid(geom) 
                          from ref.tr_fishingarea_fia
                          WHERE fia_level = 'Division'") %>%
  sf::st_transform(4326) 
save(fishing_areas_division, file="data/fishing_areas_division.Rdata")
}

crs_string <- "+proj=ortho +lon_0=-30 +lat_0=30"


ocean <- sf::st_point(x = c(0,0)) %>%
  sf::st_buffer(dist = 6371000) %>%
  sf::st_sfc(crs = crs_string)
  
area_sf2 <-  fishing_areas_division %>% 
  sf::st_intersection(ocean %>% sf::st_transform(4326)) %>% 
  sf::st_transform(crs = crs_string) 

g <- ggplot() + 
  geom_sf(data = ocean, fill = "deepskyblue4", color = NA) + 
  geom_sf(data = area_sf2, aes(fill = fia_code), color="white", lwd = .1) + 
  geom_sf(data = world, fill="black", color="grey20") + 
  geom_sf(data= country_sf2 , fill= "grey10",color="grey30")  +
  scale_fill_discrete(guide = "none") +
  theme_void()

png(filename="images/fig-fishingareas_division.png", bg="transparent")
print(g)
dev.off() 

```


![Map of ICES fishing areas at division level, source NAFO, FAO, ICES, GFCM.](images/fig-fishingareas_division.png "A planisphere with ocean fishing division"){#fig-fishingareas_division}

```{r fig-fishingareas_subdivision}
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to create a map of fishing areas at subdivision level
#| fig-cap: Map of ICES fishing areas at subdivision level, source NAFO, FAO, ICES, GFCM.

if (file.exists("data/fishingareas_subdivision.Rdata")) load("data/fishingareas_subdivision.Rdata") else {
fishing_areas_subdivision <- sf::st_read(con_diaspara,
                          query = "SELECT fia_code, ST_MakeValid(geom) 
                          from ref.tr_fishingarea_fia
                          WHERE fia_level = 'Subdivision'") %>%
  sf::st_transform(4326) 
save(fishing_areas_subdivision, file="data/fishing_areas_subdivision.Rdata")
}

crs_string <- "+proj=ortho +lon_0=-30 +lat_0=30"


ocean <- sf::st_point(x = c(0,0)) %>%
  sf::st_buffer(dist = 6371000) %>%
  sf::st_sfc(crs = crs_string)
  
area_sf2 <-  fishing_areas_subdivision %>% 
  sf::st_intersection(ocean %>% sf::st_transform(4326)) %>% 
  sf::st_transform(crs = crs_string) 

g <- ggplot() + 
  geom_sf(data = ocean, fill = "deepskyblue4", color = NA) + 
  geom_sf(data = area_sf2, aes(fill = fia_code), color= "white", lwd = .1) + 
  geom_sf(data = world, fill="black", color="grey20") + 
  geom_sf(data= country_sf2 , fill= "grey10",color="grey30")  +
  scale_fill_discrete(guide = "none") +
  theme_void()

png(filename="images/fig-fishingareas_subdivision.png", bg="transparent")
print(g)
dev.off() 
```

![Map of ICES fishing areas at subdivision level, source NAFO, FAO, ICES, GFCM.](images/fig-fishingareas_subdivision.png "A planisphere with ocean fishing subdivision"){#fig-fishingareas_subdivision}



# SCHEMA datnas and refnas

## Create referential for WGNAS

 <details> 

<summary>Creating the referential for WGNAS
</summary>
```{.sql include="../SQL/3_refnas.sql"}
```
</details> 
[//]: # IS THIS WORKING AS A COMMENT ?

## Import the metadata table

```{r refnas.tr_metadata_met}
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to import to refnas work in progress ...


# TODO create tr_area_are
# tr_metadata_met

metadata <- dbGetQuery(con_salmoglob, "SELECT * FROM metadata")

res <- dbGetQuery(con_diaspara, "SELECT * FROM datnas.tr_metadata_met;")
clipr::write_clip(colnames(res))

# unique(metadata$metric)
# dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_metric_mtr")

tr_metadata_met <-
    data.frame(
        met_var = metadata$var_mod,
        met_spe_code = "SAL",
        met_wkg_code = "WGNAS",
        met_ver_code = "SAL-2024-1", # no data on version in metadata
        met_oty_code = metadata$type_object,
         met_nim_code =  case_when(
            "Data_nimble"== metadata$nimble ~ "Data",
            "Const_nimble" == metadata$nimble ~ "Parameter constant",
            "Output" == metadata$nimble ~ "Output",
            "other" == metadata$nimble ~ "Other",
            .default = NA),
        met_dim = paste0(
            "{", metadata$dim1, ",",
            replace_na(metadata$dim2, 0), ",",
            replace_na(metadata$dim3, 0), "}"
        ),
        met_dimname = paste0(
            "{'", metadata$name_dim1, "',",
            ifelse(metadata$name_dim2 == "", "NULL", paste0("'", metadata$name_dim2, "'")), ",",
            ifelse(metadata$name_dim3 == "", "NULL", paste0("'", metadata$name_dim3, "'")), "}"
        ),
        met_modelstage = metadata$model_stage,
        met_type = metadata$type,
        met_location = metadata$locations,
        met_fishery = metadata$fishery,
        met_mtr_code = case_when(metadata$metric == "Standard deviation" ~ "SD",
            metadata$metric == "Coefficient of variation" ~ "CV",
            .default = metadata$metric
        ),
        met_des_code = NA,
        met_uni_code = NA, # (TODO)
        met_cat_code = case_when(
            grepl("Origin distribution in sea catches", metadata$type) ~ "Other",
            grepl("catch", metadata$type) ~ "Catch",
            grepl("harvest rates", metadata$type) ~ "Mortality",
            grepl("Survival rate", metadata$type) ~ "Mortality",
            grepl("Returns", metadata$type) ~ "Count",
            grepl("Fecundity", metadata$type) ~ "Life trait",
            grepl("Sex ratio", metadata$type) ~ "Life trait",
            grepl("Maturation rate", metadata$type) ~ "Life trait",
            grepl("Proportion", metadata$type) ~ "Other",
            grepl("Stocking", metadata$type) ~ "Count",
            grepl("Smolt age structure", metadata$type) ~ "Life trait",
            grepl("Time spent", metadata$type) ~ "Life trait",
            grepl("Conservation limits", metadata$type) ~ "Conservation limit",
            grepl("Abundance", metadata$type) ~ "Count",
            grepl("Demographic transitions", metadata$type) ~ "Other",
            grepl("year", metadata$type) ~ "Other",
            grepl("Number of SU", metadata$type) ~ "Other",
            grepl("Prior", metadata$type) ~ "Other",
            grepl("Number of SU", metadata$type) ~ "Other",
            .default = NA
        ),
        met_definition = metadata$definition,
        met_deprecated = NA
        
    )

res <- dbWriteTable(con_diaspara_admin, "tr_metadata_met_temp", 
tr_metadata_met, overwrite = TRUE)
dbExecute(con_diaspara_admin, "INSERT INTO refnas.tr_metadata_met 
SELECT 
 met_var,
 met_spe_code,
 met_wkg_code,
 met_ver_code,
 upper(substring(met_oty_code from 1 for 1)) ||
          substring(met_oty_code from 2 for length(met_oty_code)), 
 met_nim_code,
 met_dim::INTEGER[], 
 met_dimname::TEXT[], 
 met_modelstage, 
 met_type,
 met_location, 
 met_fishery, 
 met_mtr_code, 
 met_des_code, 
 met_uni_code,
 met_cat_code, 
 met_definition, 
 met_deprecated
FROM tr_metadata_met_temp")

dbExecute(con_diaspara_admin, "DROP TABLE tr_metadata_temp CASCADE;")

```

:::{.callout-note appearance="simple"}
## TODO diaspara: Integrate new data from REFNAS
Collect the latest version of the db from Jerome, there are new variables there.
:::

After integration,, the table of metadata from WGNAS is not changed much, apart from adapting to the new referentials. The table is show in Table @tbl-metadata.


```{r}
#| label: tbl-metadatawgnas
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Content of the refnas metadata table

dbGetQuery(con_diaspara, "SELECT * FROM refnas.tr_metadata_met limit 10;")%>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

``` 


# Import the `database` table from the salmoglob (WGNAS) database

For data we first need to create the table.

The code for creating `t_stock_sto` is listed below

<details> 

<summary>SQL code to create tables (work in progress ....)</summary>

```{.sql include="../SQL/4_stock.sql"}
```
</details> 


While creating the table, we stumbled on some issues (which we have put on the github site for details):

* [duplicated values in archive DB](https://github.com/DIASPARAproject/WP3_migdb/issues/15)

Some of the variables in salmoglob have no `year` dimension, this leads to dropping 
the non null constraint on year. We need to check for possible impact in the eel db.

* [NULL values allowed for year](https://github.com/DIASPARAproject/WP3_migdb/issues/14)

## Import the stock_sto

```{r refnas.t_stock_sto}
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE
#| code-fold: TRUE
#| code-summary: Code to import salmoglob main db into the new database.


# TODO create tr_area_are
# tr_metadata_met

stock <- dbGetQuery(con_salmoglob, "SELECT * FROM database")

res <- dbGetQuery(con_diaspara, "SELECT * FROM datnas.tr_metadata_met;")
clipr::write_clip(colnames(res))

# unique(metadata$metric)
# dbGetQuery(con_diaspara, "SELECT * FROM ref.tr_metric_mtr")

tr_metadata_met <-
    data.frame(
        met_var = metadata$var_mod,
        met_spe_code = "SAL",
        met_wkg_code = "WGNAS",
        met_ver_code = "SAL-2024-1", # no data on version in metadata
        met_oty_code = metadata$type_object,
         met_nim_code =  case_when(
            "Data_nimble"== metadata$nimble ~ "Data",
            "Const_nimble" == metadata$nimble ~ "Parameter constant",
            "Output" == metadata$nimble ~ "Output",
            "other" == metadata$nimble ~ "Other",
            .default = NA),
        met_dim = paste0(
            "{", metadata$dim1, ",",
            replace_na(metadata$dim2, 0), ",",
            replace_na(metadata$dim3, 0), "}"
        ),
        met_dimname = paste0(
            "{'", metadata$name_dim1, "',",
            ifelse(metadata$name_dim2 == "", "NULL", paste0("'", metadata$name_dim2, "'")), ",",
            ifelse(metadata$name_dim3 == "", "NULL", paste0("'", metadata$name_dim3, "'")), "}"
        ),
        met_modelstage = metadata$model_stage,
        met_type = metadata$type,
        met_location = metadata$locations,
        met_fishery = metadata$fishery,
        met_mtr_code = case_when(metadata$metric == "Standard deviation" ~ "SD",
            metadata$metric == "Coefficient of variation" ~ "CV",
            .default = metadata$metric
        ),
        met_des_code = NA,
        met_uni_code = NA, # (TODO)
        met_cat_code = case_when(
            grepl("Origin distribution in sea catches", metadata$type) ~ "Other",
            grepl("catch", metadata$type) ~ "Catch",
            grepl("harvest rates", metadata$type) ~ "Mortality",
            grepl("Survival rate", metadata$type) ~ "Mortality",
            grepl("Returns", metadata$type) ~ "Count",
            grepl("Fecundity", metadata$type) ~ "Life trait",
            grepl("Sex ratio", metadata$type) ~ "Life trait",
            grepl("Maturation rate", metadata$type) ~ "Life trait",
            grepl("Proportion", metadata$type) ~ "Other",
            grepl("Stocking", metadata$type) ~ "Count",
            grepl("Smolt age structure", metadata$type) ~ "Life trait",
            grepl("Time spent", metadata$type) ~ "Life trait",
            grepl("Conservation limits", metadata$type) ~ "Conservation limit",
            grepl("Abundance", metadata$type) ~ "Count",
            grepl("Demographic transitions", metadata$type) ~ "Other",
            grepl("year", metadata$type) ~ "Other",
            grepl("Number of SU", metadata$type) ~ "Other",
            grepl("Prior", metadata$type) ~ "Other",
            grepl("Number of SU", metadata$type) ~ "Other",
            .default = NA
        ),
        met_definition = metadata$definition,
        met_deprecated = NA
        
    )

res <- dbWriteTable(con_diaspara_admin, "tr_metadata_met_temp", 
tr_metadata_met, overwrite = TRUE)
dbExecute(con_diaspara_admin, "INSERT INTO refnas.tr_metadata_met 
SELECT 
 met_var,
 met_spe_code,
 met_wkg_code,
 met_ver_code,
 upper(substring(met_oty_code from 1 for 1)) ||
          substring(met_oty_code from 2 for length(met_oty_code)), 
 met_nim_code,
 met_dim::INTEGER[], 
 met_dimname::TEXT[], 
 met_modelstage, 
 met_type,
 met_location, 
 met_fishery, 
 met_mtr_code, 
 met_des_code, 
 met_uni_code,
 met_cat_code, 
 met_definition, 
 met_deprecated
FROM tr_metadata_met_temp")

dbExecute(con_diaspara_admin, "DROP TABLE tr_metadata_temp CASCADE;")

```



# WORK IN PROGRESS....

This document is still in construction
![Structure of the db (still in construction)](images\diaspara-ref.png){#fig-ref}

# Acknowledgements

* Data source : EuroGeographics and UN-FAO for countries









