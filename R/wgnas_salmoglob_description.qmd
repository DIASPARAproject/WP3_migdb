---
title: "WGNAS database description"
subtitle: "DIASPARA WP3.2 working document"
author: "Briand Cédric, Oliviero Jules, Helminen Jani"
date: last-modified
date-format: "[Last Updated on] DD-MM-YYYY"
description: "Technical analysis of the salmoglob database"
title-block-banner: "images/diaspara_bandeau.png"
title-block-banner-color: "white"
format:
 html:
  self-contained: true
  theme: styles.scss
  smooth-scroll: true
  fontcolor: black
  toc: true
  toc-location: left
  toc-title: Summary
  toc-depth: 3
reference-location: document
bibliography: diaspara.bib
---


The following working document is just a technical analysis of the WGNAS database (and further its graphical interface) [@ices_second_2024]. It uses different sources, ICES vocabulary, the stock annex [@ICES2021_wgnas_stock_annex], to analyse the structure of the wgnas database before integrating in a single database (wgnas, wgbast, wgeel) in the DIASPARA project.
This document does not engage the WGNAS it's just a technical analysis, to try to get how this works.
This document is listed as a task there :
https://github.com/DIASPARAproject/WP3_migdb/issues/11


```{r init}
#| echo: FALSE
#| warning: FALSE
#| message: FALSE
#| results: 'hide'

#if (!grepl("montepomi", getwd())) {
if(Sys.info()[["user"]] == 'joliviero'){
setwd("D:/workspace/DIASPARA_WP3_migdb/R")
} else if (Sys.info()[["user"]] == 'cedric.briand'){
setwd("C:/workspace/DIASPARA_WP3_migdb/R")
}
source("utilities/load_library.R")
load_library("RPostgres")
load_library("sf")
load_library("getPass")
load_library("readxl")
load_library("flextable")
load_library("tidyverse")
load_library("yaml")
load_library("DBI")
load_library("knitr")
load_library("kableExtra")
load_library("DT")
cred=read_yaml("../credentials.yml")
con_salmoglob = dbConnect(Postgres(), dbname=cred$dbnamesalmo,host=cred$host,port=cred$port,user=cred$usersalmo, password=cred$passwordsalmo)
```

# Main database structure

When loading the first lines of the db, it really looks as following :

```{r tbl-databasedescription}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: 'Structure of the WGNAS main database'
database10 <- DBI::dbGetQuery(con_salmoglob, 'SELECT * FROM public.database limit 20')
knitr::kable(database10) %>% kable_styling(bootstrap_options = c("striped","hover", "condensed"))
```

# Area

::: {#fig-phylogeographicstructures}

![](images/phylogeographic_structuring_salmon.png)

Phylogeographic structuring observed across studies in Atlantic salmon resolved by screening of phylogenetically informative nuclear microsatellite and SNP variation.
:::

We first analyse the types of area that are found in the database. These are the possible geographical locations.

From (@rivot_hierarchical_2021) :
> The model considers the dynamics of 25 SU (subscript r = 1, ... , N with N=25) (Fig. 1):  
> * 6 SU from NA CSG, indexed by r = 1, ..., 6: 1 = Newfoundland, 2 = Gulf, 3 = Scotia-Fundy, 4 =  USA, 5 = Quebec and 6 = Labrador;  
> * 8 SU from the SE CSG, indexed by r = 7, ..., 14: 7 = France, 8 = UK England and Wales, 9 =  Ireland, 10 = UK Northern Ireland - FO, 11 = UK Northern Ireland - FB, 12 = UK Scotland East,  13 = UK Scotland West, 14 = Iceland South-West;  
> * 11 SU from NE CSG, indexed by r= 15, ..., 25: 15 = Iceland North-East, 16 = Sweden, 17 =  Norway South-East, 18 = Norway South-West, 19 = Norway Middle, 20 = Norway North, 21 =  Finland, 22 = Russia Kola Barents, 23 = Russia Kola White Sea, 24 = Russia Arkhangelsk Karelia  and 25 = Russia River Pechora.  SU are defined on the basis of freshwater areas. All salmon within a SU are assumed to have the  same demographic parameters and to undertake a similar migration route at sea. Note that  Germany and Spain (SE CSG) are not considered at this stage because no complete series of data  are provided to ICES WGNAS by these two jurisdictions.

```{r tbl-areatypes}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Area types
#| tbl-subcap: 
#|   - Fisheries
#|   - Countries
#|   - Source area
area <- DBI::dbGetQuery(con_salmoglob, 'SELECT DISTINCT area FROM public.database')
knitr::kable(area[grep("fishery",area$area),,drop=FALSE], caption = "Area corresponding to fisheries", row.names=FALSE)
knitr::kable(area[grep("coun",area$area),,drop=FALSE], caption = "Area corresponding to countries", row.names=FALSE)
knitr::kable(area[!grepl("coun",area$area) & !grepl("fishery",area$area),,drop=FALSE], caption = "Area corresponding to source area", row.names=FALSE)
```

The latter table (@Tbl-areatypes-3) is by default, so Atlantic, NEC and NAC are included. Having a label in a reference table and a geom to associate to those labels would be very usefull.

# Location

## Locations corresponding to fisheries

```{r location}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Locations
#| tbl-subcap: 
#|   - Location corresponding to fisheries
#|   - These one are neither fishery nor area
#|   - Location corresponding to 
#| label: tbl-locations
location <- DBI::dbGetQuery(con_salmoglob, 'SELECT DISTINCT location FROM public.database')
knitr::kable(location[grep("fishe",tolower(location$location)),,drop=FALSE],  row.names=FALSE)
location_biz <- data.frame("location"=setdiff(location[!grepl("fishe",tolower(location$location)),],
  area[!grepl("coun",area$area) & !grepl("fishery",area$area),]))
knitr::kable(location_biz, caption = , row.names=FALSE)  
location_area <- data.frame("location"=intersect(location[!grepl("fishe",location$location),],
  area[!grepl("coun",area$area) & !grepl("fishery",area$area),]))
knitr::kable(location_area, row.names=FALSE)
```

Here we search for locations related to fisheries. 


:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
  QUESTION TO WGNAS
::::
::::{.questionbox-body}
 * Is there some gis reference for these fishing areas
 * Would it possible to use ICES areas there or would this reporting correspond to different boundaries ?
::::
:::

## Locations corresponding to fisheries

```{r param_biz}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| results: 'asis'
#| tbl-cap: List of parameters corresponding to neither fishery nor area (corresponding to weird table...).
#| label: tbl-weirdparameters

for (i in 1 : nrow(location_biz)){
  location_bizi <- location_biz$location[i]
  var_biz <- DBI::dbGetQuery(con_salmoglob, glue::glue_sql("SELECT distinct(var_mod) FROM public.database 
where location in ({location_bizi})", .con=con_salmoglob))
colnames(var_biz) <- location_bizi
print(kable(var_biz[,,drop=FALSE], row.names=FALSE))
}
```

Some values have been deprecated and are present in the database archive but not in the main database.
``` {r db_comparaison}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE

database <- DBI::dbGetQuery(con_salmoglob, "SELECT * FROM public.database")
database_archive <- DBI::dbGetQuery(con_salmoglob, "SELECT * FROM public.database_archive")

# List of commun columns
cols <- c("version", "year", "type", "age", "area", "location", "metric", "var_mod")

# getting values that are not present in database anymore
for (col in cols) {
  diff_values <- setdiff(database_archive[[col]], database[[col]])
  if (length(diff_values) > 0) {
    cat("Values present in database_archive but not in database for", col, "column :\n")
    print(diff_values)
  }
}
```



``` {r check_parameter_location}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Number of locations per model variables
#| label: tbl-varmodcount

result <- database %>%
  group_by(var_mod) %>%
  summarise(location_count = n_distinct(location))
knitr::kable(result) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

So in the end, only omega has 25 locations, and in this case the location corresponds to area.
This means we can get rid of the location column. For `omega` we can keep it,; so we can add a column with a foreign key to area in the parameters table where priors will be stored.

# Sea age

Salmon mature at various sea ages, typically returning to freshwater to spawn after one to three years at sea, but also sometimes at older sea ages; this varies widely between populations. Those salmon that return after one year at sea are referred to as one-sea-winter (`1SW`) salmon, or grilse, with older fish categorised as `2SW, 3SW`, etc. In practice, however, for management purposes these older sea age fish are typically aggregated and collectively referred to as multi-sea-winter (`MSW`) salmon. The sea age when salmon become sexually mature depends on genetics as well as growing conditions in the sea, and possibly freshwater, although the precise proximate factors initiating homeward migration are unknown (Hansen and Quinn, 1998). The sea age of Atlantic salmon is important in the context of stock definition since these different groups of fish have different migration routes, return at different times and are differentially exploited in fisheries. Thus, for example, it is only potential `MSW` salmon that are exploited in the distant water salmon fishery that operates off the west coast of Greenland [@ICES2021_wgnas_stock_annex].

``` {r check_age}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Age structure in the database
#| tbl-subcap: 
#|   - Number age data categorized by age
#|   - Number age data categorized by age, parameters without age, n is the number of lines in the db
#|   - Number age data categorized by age, n is the number of lines in the db
#|   - Variables using more than 1 age (e.g. from which the age cannot be derived from the variable itself.)
#| label: tbl-agecheck


summary_age <- DBI::dbGetQuery(con_salmoglob, 
  'SELECT count(*) N, age FROM public.database group by age')%>% arrange(age)
knitr::kable(summary_age, caption = "Number age data categorized by age") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

summary_age_parm <- DBI::dbGetQuery(con_salmoglob, 
  'SELECT count(*) N, age, var_mod FROM public.database group by age, var_mod order by age, var_mod') 
knitr::kable(summary_age_parm %>% filter(age=="_"), caption = "Number age data categorized by age, parameters without age, n is the number of lines in the db") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
knitr::kable(summary_age_parm %>% filter(age!="_"), caption = "Number age data categorized by age, n is the number of lines in the db") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

distinct_age_parm <- DBI::dbGetQuery(con_salmoglob, 
  "WITH t1 AS (
  SELECT age, 
  var_mod 
  FROM public.database 
  group by age, var_mod 
  order by age, var_mod ),
  t2 AS (
  SELECT age as age2, 
  var_mod as var_mod2
  FROM public.database 
  group by age, var_mod 
  order by age, var_mod)
  SELECT age, age2, var_mod from t1 JOIN t2 on t1.var_mod= t2.var_mod2 
  where age!=age2
  ")
knitr::kable(distinct_age_parm, caption = "Variables using more than 1 age (e.g. from which the age cannot be derived from the variable itself.)") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

:::{.callout-note appearance="simple"}
## NOTE
  Only `eggs, p_smolt, p_smolt_pr` and `prop_female` need an age, the other is contained in the name of the variable.
:::

:::{.callout-note appearance="simple"}
## NOTE
 So the age also covers information on maturity but the only time it is really used outside from the metadata (`eggs, smolt, prop_female`) the maturity is not necessary.
:::

:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
  QUESTION TO WGNAS
::::
::::{.questionbox-body}
  * Why is `omega` not mixed ?
  * Would it not make more sense to store `2SW` as `MSW`  (multi-sea-winter) ? So in the referential have `1SW 2SW 3SW` ... how many ? and then `MSW` ?
::::
:::

# Developmental stage

``` {r check_maturity_metadata}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Number of lines with lifestage in the metadata table
#| label: tbl-lifestagemeta


summary_lifestage_metadata <- DBI::dbGetQuery(con_salmoglob, 
  'SELECT count(*) as  n,  life_stage FROM public.metadata group by life_stage')%>% arrange(life_stage)
knitr::kable(summary_lifestage_metadata, format = "markdown") %>%
 kable_material(c("striped", "hover")) |>
  kbl() 
``` 

:::{.callout-note appearance="simple"}
## NOTE
  get rid of `Adults` replace with `Adult`.
:::

:::{.callout-note appearance="simple"}
## NOTE
  get rid of `Multiple` there is only one instance.
:::

:::{.callout-note appearance="simple"}
## NOTE
  Now there is the `PFA`, which is fine, but not really a stage.
:::



We first start by looking at the possible reference tables in ICES corresponding to both maturity and stage. Currently we have to store information about the sea age (`0SW, 1SW, 2SW, ...,MSW`) , the freshwater age (`1FW 2FW 3FW 4FW ...`).
The maturity could be stored in the metadata as it seems to be linked always with parameters. Currently in wgnas we have maturity : immature, mature, not maturing and post return. In the metadata we have `egg, smolts, spawner, adults`



:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
QUESTION TO WGNAS
::::
::::{.questionbox-body}
  * Is the correspondence mature / maturing correct or is it pre -spawing? 
  * Is the correspondence OK. Do we really need `PFA` stage or could we just describe it in the metadata ?
::::
:::

:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
QUESTION TO ICES
::::
::::{.questionbox-body}
 Could we add smolt and PFA (pre fisheries abundance) somewhere ?
::::
:::


# Metric

The metric are linked with coefficients, they don't need to be stored in the main db

``` {r check_metric}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Metric overview
#| tbl-subcap: 
#|   - Number of lines with metric in the database table
#|   - Number of lines with metric in the metadata table
#| label: tbl-metricoverview


summary_metric <- DBI::dbGetQuery(con_salmoglob, 
  'SELECT count(*) as  n,  metric FROM public.database group by metric')%>% arrange(metric)
knitr::kable(summary_metric,
 caption = "Number of lines with metric in the database table") %>%
 kable_material(c("striped", "hover"))

 summary_metric <- DBI::dbGetQuery(con_salmoglob, 
  'SELECT count(*) as  n,  metric FROM public.metadata group by metric')%>% arrange(metric)
knitr::kable(summary_metric,
 caption = "Number of lines with metric in the metadata table") %>%
 kable_material(c("striped", "hover"))

``` 

 There is a problem of correspondence between the database and metadata, detailed below where we query the database to find where the metric in metatdata, and 
 the metric in database are different :

``` {r check_metric_correspondence}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Checking correspondence between database and metadata
#| tbl-subcap: 
#|   - This row has a problem
#|   - Variables with correspondence pb for metric between the metadata and the database table
#| label: tbl-datametadatacheck

# this query didn't return as expected
 pb <- DBI::dbGetQuery(con_salmoglob, 
  "SELECT database.var_mod, 
  metadata.metric as metric_metadata, 
  database.metric as metric_database  
  FROM public.metadata 
  JOIN public.database
  ON database.var_mod=metadata.var_mod
  WHERE metadata.metric != database.metric
  ")
knitr::kable(pb,
 caption = "Variables with correspondence pb for metric between the metadata and the database table") %>%
 kable_material(c("striped", "hover"))

 pb1 <- DBI::dbGetQuery(con_salmoglob, 
  "SELECT distinct metadata.var_mod, 
  metadata.metric as metric_metadata,
  database.metric as metric_database  
  FROM public.metadata  
  left JOIN public.database
  ON database.var_mod=metadata.var_mod
  WHERE metadata.metric in ('Precision','Estimate')
  ")
knitr::kable(pb1,
 caption = "Variables with correspondence pb for metric between the metadata and the database table") %>%
 kable_material(c("striped", "hover"))

``` 
# Metadata

The metadata structure is described in table @tbl-globaldata.
``` {r tbl-globaldata}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Metadata structure 
DBI::dbGetQuery(con_salmoglob, 
  "SELECT * FROM metadata") %>%
  DT::datatable(rownames = FALSE,
              options = list(pageLength = 10))
```
Details on values inserted in the DB are described in subtables from table @tbl-globaldata2.
``` {r tbl-globaldata2}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Various values in the salmoglob metadata, description of their content
#| tbl-subcap: 
#|   - type_object
#|   - nimble
#|   - model_stage
#|   - type
#|   - locations
#|   - fishery
#|   - metric	
#|   - status	
#|   - environment
#|   - life_stage	
#|   - complex	
#|   - ages 

DBI::dbGetQuery(con_salmoglob, 
  "SELECT DISTINCT type_object FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))

DBI::dbGetQuery(con_salmoglob, 
  "SELECT DISTINCT nimble FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))

 DBI::dbGetQuery(con_salmoglob, 
 model_stage <-  "SELECT DISTINCT model_stage FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))

 DBI::dbGetQuery(con_salmoglob, 
  "SELECT DISTINCT type FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))

  DBI::dbGetQuery(con_salmoglob, 
  "SELECT DISTINCT locations FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))

  DBI::dbGetQuery(con_salmoglob, 
  "SELECT DISTINCT fishery FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))

  DBI::dbGetQuery(con_salmoglob, 
  "SELECT DISTINCT metric FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))

   DBI::dbGetQuery(con_salmoglob, 
  "SELECT DISTINCT status FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))

  DBI::dbGetQuery(con_salmoglob, 
  "SELECT DISTINCT environment FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))

   DBI::dbGetQuery(con_salmoglob, 
  "SELECT DISTINCT life_stage FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))

   DBI::dbGetQuery(con_salmoglob, 
  "SELECT DISTINCT complex FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))

  DBI::dbGetQuery(con_salmoglob, 
  "SELECT DISTINCT ages  FROM metadata") %>%
  knitr::kable() %>%
 kable_material(c("striped", "hover"))


``` 

# version

Versions are simple numbers from 1 to 14, they represent version of variables,
how does that work ?

> "The database_archive table allows for data versioning to strengthen the data security and quality. Its content matches that of the database table plus supplementary information, i.e. the date (day-month-year/hour-minute) when the data has been updated and an identifier to register the author of data updating (the corresponding information on the author, i.e. first name, name, email address and institute affiliation can be retrieved from the users table - not presented here). The database_archive table contains the data present in the database table and all its previous versions, which are referred by a **version number (one single version number by variable)**. At any time, an older version of database can hence be retrieved" (source @hernvann_wgnassalmoglob_2021).

The date time in database archive is also present in the database.
but this date time has several values both in the latest db and in the archive,
see below : (Table @tbl-version).

``` {r check_version}
#| echo: FALSE
#| eval: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Version in the database  = number of lines, narch = number of lines in the archive database, year =last year when present in column date, year_last_update = year extracted from date_time
#| tbl-subcap:  
#|   - version.
#|   - Year of data in date_time, both in database, and in database archive.
#| label: tbl-version

# this query didn't return as expected
 version <- DBI::dbGetQuery(con_salmoglob, 
  "WITH maxyear AS (SELECT count(*) as N, version, 
  max(year) as year,
  extract(year from date_time) as year_last_update
  FROM public.database
  group by version, date_time, year
  order by version)

  SELECT version,  sum(N) as N, max(year) as year, max(year_last_update) as year_last_update
  FROM maxyear Group by version order by version
  ")
knitr::kable(version,
 ) %>%
 kable_material(c("striped", "hover"))

# to which years correspond the data (2020 to 2024)
 dates_db <- DBI::dbGetQuery(con_salmoglob, 
  "SELECT count(*) as N,  
    extract(year from date_time) as year
  FROM public.database
  group by extract(year from date_time) 
  ")

 # to which years correspond the data archive (2020 to 2024)
 dates_db_archive <- DBI::dbGetQuery(con_salmoglob, 
  "SELECT count(*) as n_arch,  
    extract(year from date_time) as year
  FROM public.database_archive
  group by extract(year from date_time) ")

full_join(dates_db,dates_db_archive)   %>%
select(year, n, n_arch)  %>%
arrange(year)  %>%
knitr::kable() %>%
 kable_material(c("striped", "hover"))




``` 
:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
QUESTION TO WGNAS
::::
::::{.questionbox-body}
From the results in the database (Table @tbl-version), it's not clear what version represents here. 
What does `version` mean ? Just a version for each variable.
Values have been inserted in 2020, but it's not clear how you can identify the 
origin of data in database archive, since those same dates are in 
the database, and not really updated. Are we right ?
::::
:::

:::{.answerbox}
::::{.answerbox-header}
::::{.answerbox-icon}
::::
Answer from Pierre-Yves Hernvann
::::
::::{.answerbox-body}
In principle, this database update is performed variable by variable, that is, "var_mod" by "var_mod," as you can see in the table. For example, we choose to update the values ​​of the sea returns of salmon that have spent two winters at sea (var_mod=="log_N6_mu") via a csv file containing the return estimates for each region for the entire time series. For practical reasons, we can also update this variable "log_N6_mu" for a specific region ("area" column). The file we upload then contains the "log_N6_mu" values ​​for a single region, such as Newfoundland (NF).

When this file is uploaded with new data, it undergoes a battery of tests to ensure the consistency of format and information with what is already in the database and an upload date ("date_time" column) is assigned. If these tests are passed successfully, the database rows corresponding to the "var_mod" or the "var_mod" / "area" pair are deleted and replaced with those of the updated csv file. This replacement is accompanied by the incrementation of the version number (by 1) which makes it possible to determine that the update dated "date_time" constitutes the Xth modification of the variable ("var_mod" or "var_mod" / "area" pair). The archive table (which I don't think you'll be able to access) contains all versions (with version numbers and dates) of the table used by the WGNAS (it's therefore a long table created by appending all updated versions of the WGNAS table).

IN SUMMARY:
- The version number is a strictly positive integer used to track updates to the data available in the database used by the WGNAS.
- A version number is not specific to the entire database (not everything is updated every year; some information may be updated several times a year).
- A version number is specific to a "var_mod" or a "var_mod" / "area" pair. Thus, in most cases, a "var_mod" will be characterized by the same "version" index, but some "var_mod" may have different version numbers depending on the region.
- For a triplet, "version"/"var_mod"/"area" there is only one "date_time" indicating the date and time to the nearest second.
::::
:::





:::{.callout-note appearance="simple"}
## TODO
Remove NA, -, and main ? from fishery
:::

:::{.questionbox}
::::{.questionbox-header}
::::{.questionbox-icon}
::::
  QUESTION TO WGNAS
::::
::::{.questionbox-body}
In the metadata column fishery what is 'main' ? Should we remove NA and - and 
leave it NULL ?
::::
:::
## Other comments.

Currently stage in metadata not consistent, replicates information about maturity 
but not always. The lack of consistency in the metadata is not a problem as this 
table only serves as a reference to describe `var_mod` used in the database table. 

Additional values about maturity, stage, can be stored in the metadata table.

There is a discrepancy between data in the historical dataset and the current, 
so we need to create additional parameters (in the metadata table) for the historical
 database and this will need to be checked.



